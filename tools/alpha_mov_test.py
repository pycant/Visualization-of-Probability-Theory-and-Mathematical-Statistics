import cv2
import numpy as np
from PIL import Image
import os
import subprocess
import json
import tempfile

def check_video_alpha_with_ffprobe(video_path):
    """
    ä½¿ç”¨FFprobeæ£€æŸ¥è§†é¢‘æ˜¯å¦åŒ…å«alphaé€šé“ (æ”¯æŒHEVC Alpha)
    """
    try:
        cmd = [
            'ffprobe', 
            '-v', 'quiet',
            '-print_format', 'json',
            '-show_streams',
            video_path
        ]
        
        result = subprocess.run(cmd, capture_output=True, text=True, encoding='utf-8', errors='ignore')
        
        if result.returncode != 0:
            print(f"FFprobeåˆ†æå¤±è´¥: {result.stderr}")
            return False, {}
        
        try:
            data = json.loads(result.stdout)
        except json.JSONDecodeError as e:
            print(f"JSONè§£æå¤±è´¥: {e}")
            return False, {}
        
        for stream in data.get('streams', []):
            if stream.get('codec_type') == 'video':
                codec_name = stream.get('codec_name', '')
                pix_fmt = stream.get('pix_fmt', '')
                
                print(f"è§†é¢‘ç¼–è§£ç å™¨: {codec_name}")
                print(f"åƒç´ æ ¼å¼: {pix_fmt}")
                
                # æ£€æŸ¥HEVC Alphaæ”¯æŒçš„åƒç´ æ ¼å¼
                hevc_alpha_formats = ['yuva420p', 'yuva422p', 'yuva444p', 'yuva420p10le', 'yuva422p10le', 'yuva444p10le']
                # å…¶ä»–alphaæ ¼å¼
                other_alpha_formats = ['rgba', 'argb', 'bgra', 'abgr', 'ya', 'gbra']
                
                all_alpha_formats = hevc_alpha_formats + other_alpha_formats
                has_alpha = any(alpha_fmt in pix_fmt.lower() for alpha_fmt in all_alpha_formats)
                
                stream_info = {
                    'codec': codec_name,
                    'pixel_format': pix_fmt,
                    'has_alpha': has_alpha,
                    'is_hevc': codec_name.lower() in ['hevc', 'h265'],
                    'width': stream.get('width'),
                    'height': stream.get('height'),
                    'nb_frames': stream.get('nb_frames', 'N/A')
                }
                
                if has_alpha:
                    if codec_name.lower() in ['hevc', 'h265']:
                        print("âœ… æ£€æµ‹åˆ°HEVC Alphaè§†é¢‘")
                    else:
                        print(f"âœ… æ£€æµ‹åˆ°Alphaé€šé“ ({codec_name})")
                else:
                    print("âŒ æœªæ£€æµ‹åˆ°Alphaé€šé“")
                
                return has_alpha, stream_info
        
        return False, {}
        
    except Exception as e:
        print(f"FFprobeæ£€æŸ¥è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {e}")
        return False, {}

def extract_alpha_frame_ffmpeg(video_path, output_path=None, frame_number=1):
    """
    ä½¿ç”¨FFmpegæå–å¸¦alphaé€šé“çš„å¸§
    """
    try:
        if output_path is None:
            with tempfile.NamedTemporaryFile(suffix='.png', delete=False) as temp_file:
                output_path = temp_file.name
        
        cmd = [
            'ffmpeg',
            '-i', video_path,
            '-vf', f'select=eq(n\\,{frame_number-1})',
            '-vframes', '1',
            '-pix_fmt', 'rgba',  # å¼ºåˆ¶è¾“å‡ºä¸ºRGBAæ ¼å¼
            '-y',
            output_path
        ]
        
        result = subprocess.run(cmd, capture_output=True, text=True, encoding='utf-8', errors='ignore')
        
        if result.returncode != 0:
            print(f"FFmpegå¸§æå–å¤±è´¥: {result.stderr}")
            return False, None, None
        
        # åˆ†ææå–çš„å¸§
        if os.path.exists(output_path):
            with Image.open(output_path) as img:
                if img.mode == 'RGBA':
                    alpha_channel = np.array(img)[:, :, 3]
                    
                    # åˆ†æalphaé€šé“
                    unique_alpha = np.unique(alpha_channel)
                    min_alpha = np.min(alpha_channel)
                    max_alpha = np.max(alpha_channel)
                    
                    transparent_pixels = np.sum(alpha_channel < 255)
                    total_pixels = alpha_channel.size
                    transparency_ratio = transparent_pixels / total_pixels
                    
                    alpha_info = {
                        'unique_values': len(unique_alpha),
                        'alpha_range': [int(min_alpha), int(max_alpha)],
                        'transparency_ratio': transparency_ratio,
                        'has_transparency': transparency_ratio > 0
                    }
                    
                    print(f"æå–å¸§æ¨¡å¼: {img.mode}")
                    print(f"Alphaå€¼èŒƒå›´: [{min_alpha}, {max_alpha}]")
                    print(f"é€æ˜åƒç´ æ¯”ä¾‹: {transparency_ratio:.2%}")
                    
                    return True, alpha_info, output_path
                else:
                    print(f"æå–å¸§æ¨¡å¼: {img.mode} (æ— alphaé€šé“)")
                    return False, None, output_path
        
        return False, None, None
        
    except Exception as e:
        print(f"å¸§æå–è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {e}")
        return False, None, None

def check_mov_alpha_channel_opencv(video_path):
    """
    ä½¿ç”¨OpenCVæ£€æŸ¥.movè§†é¢‘æ˜¯å¦åŒ…å«é€æ˜é€šé“
    """
    try:
        # æ‰“å¼€è§†é¢‘æ–‡ä»¶
        cap = cv2.VideoCapture(video_path)
        
        if not cap.isOpened():
            print(f"æ— æ³•æ‰“å¼€è§†é¢‘æ–‡ä»¶: {video_path}")
            return False
        
        # è¯»å–ç¬¬ä¸€å¸§
        ret, frame = cap.read()
        
        if not ret:
            print("æ— æ³•è¯»å–è§†é¢‘å¸§")
            cap.release()
            return False
        
        # æ£€æŸ¥å¸§çš„é€šé“æ•°
        channels = frame.shape[2] if len(frame.shape) == 3 else 1
        
        print(f"è§†é¢‘å¸§å½¢çŠ¶: {frame.shape}")
        print(f"é€šé“æ•°: {channels}")
        
        # å¦‚æœæœ‰4ä¸ªé€šé“ï¼Œé€šå¸¸è¡¨ç¤ºåŒ…å«alphaé€šé“
        if channels == 4:
            print("æ£€æµ‹åˆ°4ä¸ªé€šé“ - å¯èƒ½åŒ…å«é€æ˜é€šé“")
            
            # è¿›ä¸€æ­¥éªŒè¯ï¼šæ£€æŸ¥alphaé€šé“æ˜¯å¦åŒ…å«é255çš„å€¼
            alpha_channel = frame[:, :, 3]
            unique_alpha_values = np.unique(alpha_channel)
            
            print(f"Alphaé€šé“å”¯ä¸€å€¼: {unique_alpha_values}")
            
            # å¦‚æœalphaé€šé“æœ‰ä¸ç­‰äº255çš„å€¼ï¼Œè¯´æ˜æœ‰é€æ˜åƒç´ 
            if len(unique_alpha_values) > 1 or (len(unique_alpha_values) == 1 and unique_alpha_values[0] != 255):
                print("ç¡®è®¤ï¼šè§†é¢‘åŒ…å«é€æ˜èƒŒæ™¯")
                has_transparency = True
            else:
                print("è™½ç„¶æœ‰4ä¸ªé€šé“ï¼Œä½†æ‰€æœ‰åƒç´ éƒ½æ˜¯ä¸é€æ˜çš„")
                has_transparency = False
                
        elif channels == 3:
            print("åªæœ‰3ä¸ªé€šé“ - ä¸åŒ…å«é€æ˜é€šé“")
            has_transparency = False
        else:
            print(f"æœªçŸ¥é€šé“æ•°: {channels}")
            has_transparency = False
        
        cap.release()
        return has_transparency
        
    except Exception as e:
        print(f"æ£€æŸ¥è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {e}")
        return False

def detailed_alpha_analysis(video_path, sample_frames=5):
    """
    å¯¹è§†é¢‘è¿›è¡Œè¯¦ç»†çš„é€æ˜é€šé“åˆ†æ
    """
    cap = cv2.VideoCapture(video_path)
    
    if not cap.isOpened():
        return
    
    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
    fps = cap.get(cv2.CAP_PROP_FPS)
    
    print(f"\n=== è§†é¢‘è¯¦ç»†ä¿¡æ¯ ===")
    print(f"æ€»å¸§æ•°: {total_frames}")
    print(f"å¸§ç‡: {fps}")
    print(f"é‡‡æ ·åˆ†æ {min(sample_frames, total_frames)} å¸§")
    
    transparency_found = False
    
    for i in range(min(sample_frames, total_frames)):
        ret, frame = cap.read()
        if not ret:
            break
            
        if len(frame.shape) == 3 and frame.shape[2] == 4:
            alpha = frame[:, :, 3]
            
            # ç»Ÿè®¡é€æ˜åƒç´ 
            transparent_pixels = np.sum(alpha < 255)
            total_pixels = alpha.shape[0] * alpha.shape[1]
            transparency_ratio = transparent_pixels / total_pixels
            
            print(f"å¸§ {i+1}: é€æ˜åƒç´  {transparent_pixels}/{total_pixels} ({transparency_ratio:.2%})")
            
            if transparent_pixels > 0:
                transparency_found = True
                # æ˜¾ç¤ºé€æ˜åº¦çš„ç»Ÿè®¡ä¿¡æ¯
                print(f"  Alphaå€¼èŒƒå›´: [{np.min(alpha)}, {np.max(alpha)}]")
    
    cap.release()
    return transparency_found

def comprehensive_alpha_detection(video_path):
    """
    ç»¼åˆalphaé€šé“æ£€æµ‹ï¼Œç‰¹åˆ«æ”¯æŒHEVC Alpha
    """
    print(f"\n{'='*60}")
    print(f"ç»¼åˆAlphaé€šé“æ£€æµ‹: {os.path.basename(video_path)}")
    print(f"{'='*60}")
    
    if not os.path.exists(video_path):
        print(f"âŒ è§†é¢‘æ–‡ä»¶ä¸å­˜åœ¨: {video_path}")
        return False
    
    results = {}
    
    # 1. FFprobeæ£€æµ‹ (æœ€å‡†ç¡®ï¼Œæ”¯æŒHEVC Alpha)
    print("\nğŸ” æ–¹æ³•1: FFprobeåˆ†æ")
    print("-" * 30)
    has_alpha_ffprobe, stream_info = check_video_alpha_with_ffprobe(video_path)
    results['ffprobe'] = {'has_alpha': has_alpha_ffprobe, 'info': stream_info}
    
    # 2. FFmpegå¸§æå–æ£€æµ‹
    print("\nğŸ” æ–¹æ³•2: FFmpegå¸§æå–åˆ†æ")
    print("-" * 30)
    success, alpha_info, frame_path = extract_alpha_frame_ffmpeg(video_path)
    results['ffmpeg_frame'] = {'success': success, 'alpha_info': alpha_info}
    
    # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
    if frame_path and os.path.exists(frame_path):
        try:
            os.unlink(frame_path)
        except:
            pass
    
    # 3. OpenCVæ£€æµ‹ (ä½œä¸ºå¯¹æ¯”)
    print("\nğŸ” æ–¹æ³•3: OpenCVåˆ†æ (å¯¹æ¯”)")
    print("-" * 30)
    opencv_result = check_mov_alpha_channel_opencv(video_path)
    results['opencv'] = opencv_result
    
    # ç»¼åˆç»“è®º
    print("\nğŸ“Š æ£€æµ‹ç»“æœæ±‡æ€»")
    print("-" * 30)
    
    if stream_info:
        print(f"è§†é¢‘ä¿¡æ¯:")
        print(f"  ç¼–è§£ç å™¨: {stream_info.get('codec', 'Unknown')}")
        print(f"  åƒç´ æ ¼å¼: {stream_info.get('pixel_format', 'Unknown')}")
        print(f"  åˆ†è¾¨ç‡: {stream_info.get('width', '?')}x{stream_info.get('height', '?')}")
        print(f"  æ˜¯å¦HEVC: {'æ˜¯' if stream_info.get('is_hevc') else 'å¦'}")
    
    # æœ€ç»ˆåˆ¤æ–­
    final_has_alpha = has_alpha_ffprobe or (success and alpha_info and alpha_info.get('has_transparency', False))
    
    if final_has_alpha:
        if stream_info.get('is_hevc'):
            print("âœ… æœ€ç»ˆç»“è®º: æ£€æµ‹åˆ°HEVC Alphaè§†é¢‘")
        else:
            print("âœ… æœ€ç»ˆç»“è®º: æ£€æµ‹åˆ°Alphaé€šé“")
    else:
        print("âŒ æœ€ç»ˆç»“è®º: æœªæ£€æµ‹åˆ°Alphaé€šé“")
    
    return final_has_alpha

# ä½¿ç”¨æ–¹æ³•
def detect_hevc_alpha_advanced(video_path):
    """
    é«˜çº§HEVC Alphaæ£€æµ‹å‡½æ•° - æ”¯æŒæ›´å¤šæ ¼å¼å’Œè¯¦ç»†åˆ†æ
    """
    try:
        cmd = ['ffprobe', '-v', 'quiet', '-print_format', 'json', '-show_streams', '-show_format', video_path]
        result = subprocess.run(cmd, capture_output=True, text=True, encoding='utf-8', errors='ignore')
        
        if result.returncode != 0:
            return False, "FFprobeåˆ†æå¤±è´¥", {}
        
        data = json.loads(result.stdout)
        
        # æ‰©å±•çš„HEVCç¼–è§£ç å™¨è¯†åˆ«
        hevc_codecs = ['hevc', 'h265', 'hvc1', 'hev1']
        
        # æ‰©å±•çš„Alphaåƒç´ æ ¼å¼æ”¯æŒ
        alpha_formats = [
            'yuva420p', 'yuva422p', 'yuva444p',
            'yuva420p10le', 'yuva422p10le', 'yuva444p10le',
            'yuva420p12le', 'yuva422p12le', 'yuva444p12le',
            'yuva420p16le', 'yuva422p16le', 'yuva444p16le'
        ]
        
        for stream in data.get('streams', []):
            if stream.get('codec_type') == 'video':
                codec = stream.get('codec_name', '').lower()
                codec_tag = stream.get('codec_tag_string', '').lower()
                pix_fmt = stream.get('pix_fmt', '').lower()
                
                # æ›´å‡†ç¡®çš„HEVCæ£€æµ‹
                is_hevc = (codec in hevc_codecs or 
                          codec_tag in hevc_codecs or
                          'hevc' in codec or 'h265' in codec)
                
                # æ›´å‡†ç¡®çš„Alphaæ£€æµ‹
                has_alpha = any(fmt in pix_fmt for fmt in alpha_formats)
                
                # æå–ä½æ·±åº¦ä¿¡æ¯
                bit_depth = 8
                if '10le' in pix_fmt or '10be' in pix_fmt:
                    bit_depth = 10
                elif '12le' in pix_fmt or '12be' in pix_fmt:
                    bit_depth = 12
                elif '16le' in pix_fmt or '16be' in pix_fmt:
                    bit_depth = 16
                
                # è¯¦ç»†ä¿¡æ¯
                details = {
                    'codec': codec,
                    'codec_tag': codec_tag,
                    'pixel_format': pix_fmt,
                    'width': stream.get('width', 0),
                    'height': stream.get('height', 0),
                    'bit_depth': bit_depth,
                    'fps': stream.get('r_frame_rate', '0/1'),
                    'container': data.get('format', {}).get('format_name', 'unknown')
                }
                
                if is_hevc and has_alpha:
                    return True, f"HEVC Alpha ({bit_depth}bit)", details
                elif has_alpha:
                    return True, f"{codec.upper()} Alpha ({bit_depth}bit)", details
                elif is_hevc:
                    return False, f"HEVC ({bit_depth}bit, æ— Alpha)", details
                else:
                    return False, f"{codec.upper()} ({bit_depth}bit, æ— Alpha)", details
        
        return False, "æœªæ‰¾åˆ°è§†é¢‘æµ", {}
        
    except Exception as e:
        return False, f"æ£€æµ‹é”™è¯¯: {e}", {}

def get_conversion_suggestions(video_details, has_alpha, alpha_type):
    """
    æ ¹æ®è§†é¢‘ä¿¡æ¯æä¾›è½¬æ¢å»ºè®®
    """
    suggestions = []
    
    if "HEVC Alpha" in alpha_type:
        suggestions.append("âœ… å·²ç»æ˜¯HEVC Alphaæ ¼å¼ï¼Œæ— éœ€è½¬æ¢")
        suggestions.append("ğŸ’¡ å¦‚éœ€ä¼˜åŒ–å¯ä»¥è°ƒæ•´ä½æ·±åº¦æˆ–å‹ç¼©å‚æ•°")
    elif "HEVC" in alpha_type and not has_alpha:
        suggestions.append("ğŸ’¡ HEVCè§†é¢‘ï¼Œå¯ä»¥æ·»åŠ Alphaé€šé“:")
        suggestions.append(f"   ffmpeg -i input.{video_details.get('container', 'mp4')} -vf 'format=yuva420p' -c:v libx265 -crf 23 output_alpha.mp4")
    elif has_alpha and "HEVC" not in alpha_type:
        suggestions.append("ğŸ’¡ åŒ…å«Alphaé€šé“ï¼Œå»ºè®®è½¬æ¢ä¸ºHEVC Alphaä»¥è·å¾—æ›´å¥½å‹ç¼©:")
        if video_details.get('bit_depth', 8) > 8:
            suggestions.append(f"   ffmpeg -i input.{video_details.get('container', 'mov')} -c:v libx265 -pix_fmt yuva420p10le -crf 20 output_hevc_alpha.mp4")
        else:
            suggestions.append(f"   ffmpeg -i input.{video_details.get('container', 'mov')} -c:v libx265 -pix_fmt yuva420p -crf 23 output_hevc_alpha.mp4")
    else:
        suggestions.append("ğŸ’¡ æ ‡å‡†è§†é¢‘ï¼Œå¦‚éœ€HEVC Alphaå¯ä»¥:")
        suggestions.append("   1. æ·»åŠ é€æ˜åº¦: ffmpeg -i input.mp4 -vf 'format=yuva420p' -c:v libx265 output_alpha.mp4")
        suggestions.append("   2. è½¬æ¢ä¸ºHEVC: ffmpeg -i input.mp4 -c:v libx265 -crf 23 output_hevc.mp4")
    
    return suggestions

if __name__ == "__main__":
    print("ğŸ¬ æ”¹è¿›çš„HEVC Alphaæ£€æµ‹å™¨")
    print("=" * 60)
    print("âœ¨ æ–°å¢åŠŸèƒ½:")
    print("   â€¢ ä¸“é—¨ä¼˜åŒ–HEVC Alphaæ£€æµ‹")
    print("   â€¢ æ”¯æŒå¤šç§alphaåƒç´ æ ¼å¼")
    print("   â€¢ æ”¹è¿›çš„ç¼–ç å¤„ç†")
    print("   â€¢ è¯¦ç»†çš„å…¼å®¹æ€§åˆ†æ")
    
    # æµ‹è¯•å¤šä¸ªè§†é¢‘æ–‡ä»¶
    test_videos = [
        # r"C:\Users\12919\Desktop\å¯è§†åŒ–æ•™å­¦æ¡ˆä¾‹\static\videos\alpha_test_transparent.mov",
        # r"C:\Users\12919\Desktop\å¯è§†åŒ–æ•™å­¦æ¡ˆä¾‹\static\videos\alpha_test_mov_prores4444.mov",
        # r"C:\Users\12919\Desktop\å¯è§†åŒ–æ•™å­¦æ¡ˆä¾‹\static\videos\hevc_alpha_test.mp4",
        # r"C:\Users\12919\Desktop\å¯è§†åŒ–æ•™å­¦æ¡ˆä¾‹\static\videos\å‡åŒ€åˆ†å¸ƒ.mov",
        # r"C:\Users\12919\Desktop\å¯è§†åŒ–æ•™å­¦æ¡ˆä¾‹\static\videos\å¡æ–¹åˆ†å¸ƒ.mp4",
        # r"C:\Users\12919\Desktop\å¯è§†åŒ–æ•™å­¦æ¡ˆä¾‹\static\videos\æ³Šæ¾åˆ†å¸ƒ.mp4",
        # r"C:\Users\12919\Desktop\å¯è§†åŒ–æ•™å­¦æ¡ˆä¾‹\static\videos\æ­£æ€åˆ†å¸ƒ.mp4",
        # r"C:\Users\12919\Desktop\å¯è§†åŒ–æ•™å­¦æ¡ˆä¾‹\static\videos\æŒ‡æ•°åˆ†å¸ƒ.mp4"
        r"D:\project\æ•°å­—äººä»»åŠ¡\è¯¾ç¨‹ä»‹ç»è§†é¢‘\16.mov"
    ]
    
    alpha_videos = []
    hevc_alpha_videos = []
    hevc_videos = []
    
    video_analysis_results = []
    
    for video_path in test_videos:
        if os.path.exists(video_path):
            # ç»¼åˆAlphaæ£€æµ‹
            has_alpha = comprehensive_alpha_detection(video_path)
            if has_alpha:
                alpha_videos.append(video_path)
            
            # é«˜çº§HEVC Alphaæ£€æµ‹
            is_alpha, alpha_type, details = detect_hevc_alpha_advanced(video_path)
            
            # åˆ†ç±»ç»Ÿè®¡
            if "HEVC Alpha" in alpha_type:
                hevc_alpha_videos.append(video_path)
            elif "HEVC" in alpha_type:
                hevc_videos.append(video_path)
            
            # ä¿å­˜åˆ†æç»“æœ
            video_analysis_results.append({
                'path': video_path,
                'name': os.path.basename(video_path),
                'has_alpha': has_alpha,
                'is_alpha': is_alpha,
                'alpha_type': alpha_type,
                'details': details
            })
                
        else:
            print(f"\nâš ï¸  æ–‡ä»¶ä¸å­˜åœ¨: {os.path.basename(video_path)}")
    
    print(f"\n{'='*60}")
    print("ğŸ¯ HEVC Alphaæ£€æµ‹æ€»ç»“ (æ”¹è¿›ç‰ˆ)")
    print(f"{'='*60}")
    print(f"æ€»å…±æ£€æµ‹è§†é¢‘: {len([v for v in test_videos if os.path.exists(v)])} ä¸ª")
    print(f"åŒ…å«Alphaé€šé“: {len(alpha_videos)} ä¸ª")
    print(f"HEVCè§†é¢‘: {len(hevc_videos)} ä¸ª")
    print(f"HEVC Alphaè§†é¢‘: {len(hevc_alpha_videos)} ä¸ª")
    
    if hevc_alpha_videos:
        print(f"\nğŸŒŸ HEVC Alphaè§†é¢‘:")
        for video in hevc_alpha_videos:
            result = next(r for r in video_analysis_results if r['path'] == video)
            details = result['details']
            print(f"  ğŸ¯ {result['name']}")
            print(f"     æ ¼å¼: {details.get('pixel_format', 'unknown')} | "
                  f"åˆ†è¾¨ç‡: {details.get('width', 0)}x{details.get('height', 0)} | "
                  f"ä½æ·±åº¦: {details.get('bit_depth', 8)}bit")
    
    if alpha_videos:
        print(f"\nâœ… æ‰€æœ‰Alphaè§†é¢‘è¯¦æƒ…:")
        for video in alpha_videos:
            result = next(r for r in video_analysis_results if r['path'] == video)
            marker = "ğŸŒŸ" if "HEVC Alpha" in result['alpha_type'] else "âœ¨"
            details = result['details']
            print(f"  {marker} {result['name']} ({result['alpha_type']})")
            if details:
                print(f"     å®¹å™¨: {details.get('container', 'unknown')} | "
                      f"åƒç´ æ ¼å¼: {details.get('pixel_format', 'unknown')} | "
                      f"åˆ†è¾¨ç‡: {details.get('width', 0)}x{details.get('height', 0)}")
    
    # æä¾›è½¬æ¢å»ºè®®
    print(f"\nğŸ’¡ æ™ºèƒ½è½¬æ¢å»ºè®®:")
    print("-" * 40)
    
    for result in video_analysis_results:
        if result['details']:
            suggestions = get_conversion_suggestions(
                result['details'], 
                result['has_alpha'], 
                result['alpha_type']
            )
            
            print(f"\nğŸ“¹ {result['name']}:")
            for suggestion in suggestions:
                print(f"   {suggestion}")
    
    if not alpha_videos:
        print(f"\nğŸ”§ ç³»ç»Ÿå»ºè®®:")
        print("   â€¢ å½“å‰æ²¡æœ‰æ£€æµ‹åˆ°Alphaè§†é¢‘")
        print("   â€¢ å¯ä»¥ä½¿ç”¨ä»¥ä¸‹å·¥å…·ç”Ÿæˆæµ‹è¯•è§†é¢‘:")
        print("     - generate_hevc_alpha_test.py (ç”ŸæˆHEVC Alphaæµ‹è¯•è§†é¢‘)")
        print("     - create_real_hevc_alpha.py (åˆ›å»ºçœŸå®HEVC Alphaè§†é¢‘)")
        print("   â€¢ æ¨èä½¿ç”¨HEVC Alphaæ ¼å¼ä»¥è·å¾—æœ€ä½³å‹ç¼©å’Œå…¼å®¹æ€§")
    
    print(f"\nğŸ‰ HEVC Alphaæ£€æµ‹åŠŸèƒ½å·²å…¨é¢ä¼˜åŒ–!")
    print("âœ¨ æ–°å¢åŠŸèƒ½:")
    print("   â€¢ æ‰©å±•çš„HEVCç¼–è§£ç å™¨è¯†åˆ« (hevc, h265, hvc1, hev1)")
    print("   â€¢ æ”¯æŒ10bit/12bit/16bit Alphaæ ¼å¼")
    print("   â€¢ æ™ºèƒ½è½¬æ¢å»ºè®®ç³»ç»Ÿ")
    print("   â€¢ è¯¦ç»†çš„è§†é¢‘æµåˆ†æ")
    print("ğŸ’¡ ç°åœ¨å¯ä»¥å‡†ç¡®æ£€æµ‹å’Œåˆ†æå„ç§HEVC Alphaè§†é¢‘æ ¼å¼!")

